import os
import numpy as np
import pandas as pd
from graph_attention_replanner.config import MissionPlanConfig, LogFileConfig


"""
This script convert the data generated by `gen_data.py` to TSP/ATSP format for LKH solver.

For help:
python gen_data_td2tsp.py --help

Usage:
First generate some data using the MTSP Generator
python gen_data.py --mtsp_problem_type 5 --num_node 12 --num_task 4 --discretize_level 3 --num_agent 3 --exact_num_node --batch_size 1000 --num_exp 1

Then convert the data to TSP/ATSP format
python gen_data_td2tsp.py 
# method param
--method_mtsp_problem_type 1
# data param
--mtsp_problem_type 5 --num_node 12 --num_task 4 --discretize_level 3 --num_agent 3 --exact_num_node --batch_size 1000 --num_exp 1

Example Command:
python gen_data_td2tsp.py --method_mtsp_problem_type 1 --mtsp_problem_type 5 --num_node 12 --num_task 4 --discretize_level 3 --num_agent 3 --exact_num_node --batch_size 1000 --num_exp 1
"""


def get_distance_matrix(locs):
    """
    Given a list of 2D locations, this function returns a square matrix
    representing the Euclidean distances between the locations using an optimized approach.

    Parameters:
    locs (list or np.array): A list or array of 2D coordinates (x, y).

    Returns:
    np.array: A square matrix where element (i, j) represents the Euclidean distance between locs[i] and locs[j].
    """
    locs = np.array(locs)

    # Use broadcasting to compute pairwise differences, square them, and sum along axis
    diffs = locs[:, np.newaxis, :] - locs[np.newaxis, :, :]
    dist_matrix = np.sqrt(np.sum(diffs**2, axis=-1))

    return dist_matrix


def diagonal_mask(size):
    # Create a square matrix of True values
    mask = np.ones((size, size), dtype=bool)
    # Set the diagonal to False
    np.fill_diagonal(mask, False)
    return mask


def main():
    args = MissionPlanConfig().parse_eval_args()

    cfg = LogFileConfig(
        args.method_mtsp_problem_type,
        args.num_node,
        args.min_num_task,
        args.max_num_task,
        args.min_discretize_level,
        args.max_discretize_level,
        args.min_num_agent,
        args.max_num_agent,
        args.batch_size,
    )

    data_path = cfg.get_data_logfilename(
        seed=args.seed, format="npz", override_mtsp_problem_type=args.mtsp_problem_type
    )  # Use Problem 5 (largest) data, and trim it down to smaller problem data
    data = np.load(data_path)
    data_dict = dict(data)
    # generator 4 doesnt have this key
    unsplited_task_length = (
        data["unsplited_task_length"]
        if "unsplited_task_length" in data
        else data["task_length"]
    )

    amtsp_data_dir = cfg.get_data_lkhlogfiledir(seed=args.seed, num_exp=args.num_exp)

    data_path_str = data_path.split("/")[-1]
    for exp_idx in range(args.num_exp):
        extension = "tsp" if args.method_mtsp_problem_type == 1 else "atsp"
        exp_result_path = f"{amtsp_data_dir}/{exp_idx}.{extension}"
        if os.path.isfile(exp_result_path):
            print(
                f"WARNING: Data file already exists: {exp_result_path}. Skipping generation."
            )
            continue

        if args.method_mtsp_problem_type == 1:
            convert1(data_dict, args.num_task, exp_idx, exp_result_path, data_path_str)
        elif args.method_mtsp_problem_type == 2:
            convert2(
                data_dict,
                args.num_task,
                exp_idx,
                exp_result_path,
                data_path_str,
                unsplited_task_length=unsplited_task_length,
            )
        elif args.method_mtsp_problem_type == 3:
            convert3(data_dict, args.num_task, exp_idx, exp_result_path, data_path_str)
        elif (
            args.method_mtsp_problem_type == 4
            or args.method_mtsp_problem_type == 6
            or args.method_mtsp_problem_type == 7
        ):
            convert_everything(
                data_dict,
                args.num_task,
                exp_idx,
                exp_result_path,
                data_path_str,
                unsplited_task_length=unsplited_task_length,
                collab=False,
            )
        elif args.method_mtsp_problem_type == 5:
            convert_everything(
                data_dict,
                args.num_task,
                exp_idx,
                exp_result_path,
                data_path_str,
                unsplited_task_length=unsplited_task_length,
                collab=True,
                num_node=args.num_node,
            )


def convert1(data_dict, num_task, exp_idx, exp_result_path, data_path_str):
    nodes = data_dict["locs"][exp_idx][: num_task + 1]

    with open(exp_result_path, "w") as f:
        name = exp_result_path.split("/")[-3]
        f.write(
            f"NAME: {name}_{exp_idx}\nTYPE: TSP\nDIMENSION: {num_task + 1}\nEDGE_WEIGHT_TYPE: EUC_2D\nNODE_COORD_SECTION\n"
        )
        idx = np.arange(1, nodes.shape[0] + 1).reshape((nodes.shape[0], 1))
        node_str = np.concatenate((idx, nodes), axis=1)
        np.savetxt(f, node_str, fmt="%d", delimiter=" ")  # have to be int for tsp
        home_depot_str = str(nodes[0]).replace("\n", ",")
        locs_str = str(nodes[1:]).replace("\n", ",")
        f.write(
            f"COMMENT: home_depot: [{home_depot_str}]; locs: [{locs_str}]; from data: [{data_path_str}]\n"
        )
        f.write("EOF\n")


def convert2(
    data_dict,
    num_task,
    exp_idx,
    exp_result_path,
    data_path_str,
    unsplited_task_length=None,
):
    nodes = data_dict["locs"][exp_idx][: num_task + 1]
    task_length = unsplited_task_length[exp_idx][
        1 : num_task + 1
    ]  # ignore home depot length

    dm = get_distance_matrix(nodes)

    # Add task length to columns
    tl_counter = 0
    for i in range(1, dm.shape[1]):
        dm[:, i] += task_length[tl_counter]
        tl_counter += 1

    # Add inf and 0 to the right places
    INF = 9999

    # No self loop except for home depot
    # Agent can choose to stay at home depot
    np.fill_diagonal(dm[1:, 1:], INF)

    node_str = [f"[{x}|{y}]" for i, (x, y) in enumerate(nodes)]
    # node_str.insert(0, "[Depot LKH]")
    df = pd.DataFrame(dm, columns=node_str, index=node_str).replace(INF, "INF")
    print(df)

    with open(exp_result_path, "w") as f:
        name = exp_result_path.split("/")[-3]
        f.write(
            f"NAME: {name}_{exp_idx}\nTYPE: ATSP\nDIMENSION: {dm.shape[0]}\nEDGE_WEIGHT_TYPE: EXPLICIT\nEDGE_WEIGHT_FORMAT: FULL_MATRIX\nEDGE_WEIGHT_SECTION\n"
        )
        np.savetxt(f, dm, fmt="%10.4f", delimiter=" ")
        # start_locs_str = str(start_locs).replace("\n", ",")
        home_depot_str = str(nodes[0]).replace("\n", ",")
        locs_str = str(nodes[1:]).replace("\n", ",")
        tl_str = str(task_length[0:]).replace("\n", ",")
        f.write(
            f"COMMENT: home_depot: [{home_depot_str}]; locs: [{locs_str}]; task_length: [{tl_str}]; from data: [{data_path_str}]\n"
        )
        f.write("EOF\n")


def convert3(data_dict, num_task, exp_idx, exp_result_path, data_path_str):
    locs = data_dict["locs"][exp_idx][: num_task + 1]
    # start_locs = data_dict["locs"][exp_idx][num_task+1:]
    start_locs = data_dict["start_locs"][exp_idx]
    num_agent = data_dict["num_agent"][0]
    # task_length = data_dict[task_length_key][exp_idx][
    #     1 : num_node + 1
    # ]  # ignore home depot length

    nodes = np.insert(locs, 1, start_locs, axis=0)
    extra_home_depot_to_be_append = np.tile(locs[0], num_agent - 1).reshape(
        -1, num_agent - 1
    )
    nodes = np.insert(nodes, 1, extra_home_depot_to_be_append, axis=0)
    dm = get_distance_matrix(nodes)

    # Add task length
    # tl_counter = 0
    # for i in range(num_agent * 2, dm.shape[0]):
    #     dm[i] += task_length[tl_counter]
    #     tl_counter += 1

    # Add inf and 0 to the right places
    INF = 9999
    # No self loop
    np.fill_diagonal(dm, INF)
    # Home depot to home depot are inf
    dm[:num_agent, :num_agent] = INF
    # Initial loc to home depot are inf. Allow A to H_{A}, B to H_{B}, etc to be True Distance, so drones can go directly from initial location to home depot
    mask = diagonal_mask(num_agent)
    dm[num_agent : num_agent * 2, :num_agent][mask] = INF
    # dm[num_agent: num_agent*2, :num_agent] = INF
    # Getting to initial loc from most node is impossible except when from home depot
    dm[:, num_agent : num_agent * 2] = INF
    # From home depot to task are impossible
    dm[:num_agent, num_agent * 2 :] = INF

    # Insert an artificial node as depot for LKH, it only lead to the real home depot
    padding = np.tile(INF, dm.shape[0])
    dm = np.insert(dm, 0, padding, axis=0)
    padding = np.tile(INF, dm.shape[0])
    dm = np.insert(dm, 0, padding, axis=1)
    dm[0, num_agent + 1 : num_agent * 2 + 1] = 0

    node_str = [f"[{x}|{y}]" for i, (x, y) in enumerate(nodes)]
    node_str.insert(0, "[Depot LKH]")
    df = pd.DataFrame(dm, columns=node_str, index=node_str).replace(INF, "INF")
    print(df)

    with open(exp_result_path, "w") as f:
        name = exp_result_path.split("/")[-3]
        f.write(
            f"NAME: {name}_{exp_idx}\nTYPE: ATSP\nDIMENSION: {dm.shape[0]}\nEDGE_WEIGHT_TYPE: EXPLICIT\nEDGE_WEIGHT_FORMAT: FULL_MATRIX\nEDGE_WEIGHT_SECTION\n"
        )
        np.savetxt(f, dm, fmt="%10.4f", delimiter=" ")
        start_locs_str = str(start_locs).replace("\n", ",")
        home_depot_str = str(locs[0]).replace("\n", ",")
        locs_str = str(locs[1:]).replace("\n", ",")
        # tl_str = str(task_length[0:]).replace("\n", ",")
        f.write(
            f"COMMENT: start_locs: [{start_locs_str}]; home_depot: [{home_depot_str}]; locs: [{locs_str}]; from data: [{data_path_str}]\n"
        )
        f.write("EOF\n")


def convert_everything(
    data_dict,
    num_task,
    exp_idx,
    exp_result_path,
    data_path_str,
    unsplited_task_length=None,
    collab=False,
    num_node=None,
):
    if not collab:
        locs = data_dict["locs"][exp_idx][: num_task + 1]
        task_length = unsplited_task_length[exp_idx][
            1 : num_task + 1
        ]  # ignore home depot length
        # start_locs = data_dict["locs"][exp_idx][num_task + 1:]
    else:
        locs = data_dict["locs"][exp_idx][: num_node + 1]
        task_length = data_dict["task_length"][exp_idx][
            1 : num_node + 1
        ]  # ignore home depot length
        # start_locs = data_dict["locs"][exp_idx][num_node + 1:]

    start_locs = data_dict["start_locs"][exp_idx]
    num_agent = data_dict["num_agent"][0]

    nodes = np.insert(locs, 1, start_locs, axis=0)
    extra_home_depot_to_be_append = np.broadcast_to(
        locs[0], (num_agent - 1, nodes.shape[1])
    )
    nodes = np.insert(nodes, 1, extra_home_depot_to_be_append, axis=0)
    dm = get_distance_matrix(nodes)

    # Add task length
    tl_counter = 0
    for i in range(num_agent * 2, dm.shape[1]):
        dm[:, i] += task_length[tl_counter]
        tl_counter += 1

    # Add inf and 0 to the right places
    INF = 9999
    # No self loop
    np.fill_diagonal(dm, INF)
    # Home depot to home depot are inf
    dm[:num_agent, :num_agent] = INF
    # Initial loc to home depot are inf. Allow A to H_{A}, B to H_{B}, etc to be True Distance, so drones can go directly from initial location to home depot
    mask = diagonal_mask(num_agent)
    dm[num_agent : num_agent * 2, :num_agent][mask] = INF
    # dm[num_agent: num_agent*2, :num_agent] = INF
    # Getting to initial loc from most node is impossible except when from home depot
    dm[:, num_agent : num_agent * 2] = INF
    # From home depot to task are impossible
    dm[:num_agent, num_agent * 2 :] = INF

    # Insert an artificial node as depot for LKH, it only lead to the real home depot
    padding = np.tile(INF, dm.shape[0])
    dm = np.insert(dm, 0, padding, axis=0)
    padding = np.tile(INF, dm.shape[0])
    dm = np.insert(dm, 0, padding, axis=1)
    dm[0, num_agent + 1 : num_agent * 2 + 1] = 0

    node_str = [f"[{x}|{y}]" for i, (x, y) in enumerate(nodes)]
    node_str.insert(0, "[Depot LKH]")
    df = pd.DataFrame(dm, columns=node_str, index=node_str).replace(INF, "INF")
    print(df)

    with open(exp_result_path, "w") as f:
        name = exp_result_path.split("/")[-3]
        f.write(
            f"NAME: {name}_{exp_idx}\nTYPE: ATSP\nDIMENSION: {dm.shape[0]}\nEDGE_WEIGHT_TYPE: EXPLICIT\nEDGE_WEIGHT_FORMAT: FULL_MATRIX\nEDGE_WEIGHT_SECTION\n"
        )
        np.savetxt(f, dm, fmt="%10.4f", delimiter=" ")
        start_locs_str = str(start_locs).replace("\n", ",")
        home_depot_str = str(locs[0]).replace("\n", ",")
        locs_str = str(locs[1:]).replace("\n", ",")
        tl_str = str(task_length[0:]).replace("\n", ",")
        f.write(
            f"COMMENT: start_locs: [{start_locs_str}]; home_depot: [{home_depot_str}]; locs: [{locs_str}]; task_length: [{tl_str}]; from data: [{data_path_str}]\n"
        )
        f.write("EOF\n")


if __name__ == "__main__":
    main()
